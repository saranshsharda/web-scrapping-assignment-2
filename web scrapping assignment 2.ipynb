{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Write a python program to scrape data for “Data Analyst” Job position in \n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” \n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Driver [C:\\Users\\HP\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24\\chromedriver.exe] found in cache\n",
      "<ipython-input-89-c6118524b1c2>:17: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_company</th>\n",
       "      <th>job_locations</th>\n",
       "      <th>experience_req</th>\n",
       "      <th>job_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring Data Analysts For E commerce Platform |...</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA - Urgent Opening For Data Analyst BFSI Doma...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Hiring Data Analysts For E commerce Platform |...   \n",
       "2                                       Data Analyst   \n",
       "3  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "4  DA - Urgent Opening For Data Analyst BFSI Doma...   \n",
       "5                     Data Analyst - Informatica MDM   \n",
       "6  Assistant Vice President - MIS & Reporting ( B...   \n",
       "7                                       Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                         job_company  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                   Allegis Services India Pvt. Ltd.   \n",
       "2                                  Applied Materials   \n",
       "3   PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd   \n",
       "4                     Tata Consultancy Services Ltd.   \n",
       "5                Shell India Markets Private Limited   \n",
       "6  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...   \n",
       "7                           Myntra Designs Pvt. Ltd.   \n",
       "8                           Myntra Designs Pvt. Ltd.   \n",
       "9                           Myntra Designs Pvt. Ltd.   \n",
       "\n",
       "                                       job_locations experience_req  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...        0-3 Yrs   \n",
       "1                                Bangalore/Bengaluru        0-5 Yrs   \n",
       "2                                Bangalore/Bengaluru       7-10 Yrs   \n",
       "3                                Bangalore/Bengaluru        2-4 Yrs   \n",
       "4  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...        4-9 Yrs   \n",
       "5                                Bangalore/Bengaluru        6-9 Yrs   \n",
       "6                        Mumbai, Bangalore/Bengaluru      12-18 Yrs   \n",
       "7                                Bangalore/Bengaluru        3-6 Yrs   \n",
       "8                                Bangalore/Bengaluru        3-6 Yrs   \n",
       "9                                Bangalore/Bengaluru        4-9 Yrs   \n",
       "\n",
       "                job_salary  \n",
       "0  3,50,000 - 4,50,000 PA.  \n",
       "1            Not disclosed  \n",
       "2            Not disclosed  \n",
       "3            Not disclosed  \n",
       "4            Not disclosed  \n",
       "5            Not disclosed  \n",
       "6            Not disclosed  \n",
       "7            Not disclosed  \n",
       "8            Not disclosed  \n",
       "9            Not disclosed  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def data_analyst_scrapes(url):\n",
    "\n",
    "    opts = Options()\n",
    "\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    #url = \"https://www.naukri.com/\"\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    driver.find_element_by_id('qsb-keyword-sugg').send_keys('Data Analyst')\n",
    "    driver.find_element_by_id('qsb-location-sugg').send_keys('Bangalore')\n",
    "\n",
    "    driver.find_element_by_class_name('btn').click()\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # scraping the data:\n",
    "\n",
    "    \n",
    "    job_titles, job_company = [],[]\n",
    "\n",
    "    job_location, job_exp_req, job_sal = [],[],[]\n",
    "\n",
    "    for title in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]:\n",
    "        job_titles.append(title.text)\n",
    "\n",
    "    for company_name in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[:10]:\n",
    "        job_company.append(company_name.text)\n",
    "\n",
    "    for i,value in enumerate(driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")):\n",
    "            if i%3 == 0:\n",
    "                job_exp_req.append(value.text)\n",
    "\n",
    "            if i%3 == 1:\n",
    "                job_sal.append(value.text)\n",
    "\n",
    "            if i%3 == 2:\n",
    "                job_location.append(value.text)\n",
    "                \n",
    "            if i>28:\n",
    "                break\n",
    "                \n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame({'job_title':job_titles,'job_company':job_company,'job_locations':job_location,'experience_req':job_exp_req,'job_salary':job_sal})\n",
    "\n",
    "    return df\n",
    "\n",
    "data_analyst_scrapes('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in \n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter \n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Driver [C:\\Users\\HP\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24\\chromedriver.exe] found in cache\n",
      "<ipython-input-93-2db9eea69092>:17: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_company</th>\n",
       "      <th>job_locations</th>\n",
       "      <th>experience_req</th>\n",
       "      <th>job_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>7,00,000 - 9,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist - Credit risk</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Computational Design Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         job_title  \\\n",
       "0  Data Scientist / Data Analyst -Business Analyst   \n",
       "1                  Senior Data Scientist, Modeling   \n",
       "2                      Data Scientist - IBM Garage   \n",
       "3                                   Data Scientist   \n",
       "4                                   Data Scientist   \n",
       "5              Senior Data Scientist - Credit risk   \n",
       "6                        Big Data - Data Scientist   \n",
       "7                       SDE Lead Data Scientist-L3   \n",
       "8      Computational Design Lead Data Scientist-L3   \n",
       "9                                   Data Scientist   \n",
       "\n",
       "                          job_company  \\\n",
       "0  Inflexion Analytix Private Limited   \n",
       "1                             Nielsen   \n",
       "2              IBM India Pvt. Limited   \n",
       "3              IBM India Pvt. Limited   \n",
       "4              IBM India Pvt. Limited   \n",
       "5                  Scienaptic Systems   \n",
       "6           Xoriant Solutions Pvt Ltd   \n",
       "7   Huawei Technologies India Pvt Ltd   \n",
       "8   Huawei Technologies India Pvt Ltd   \n",
       "9              IBM India Pvt. Limited   \n",
       "\n",
       "                                       job_locations experience_req  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...        0-3 Yrs   \n",
       "1  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...        3-7 Yrs   \n",
       "2  Noida, Hyderabad/Secunderabad, Bangalore/Benga...        5-8 Yrs   \n",
       "3  Noida, Hyderabad/Secunderabad, Bangalore/Benga...        4-9 Yrs   \n",
       "4  Noida, Hyderabad/Secunderabad, Bangalore/Benga...        5-8 Yrs   \n",
       "5                                Bangalore/Bengaluru       5-10 Yrs   \n",
       "6  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...        1-3 Yrs   \n",
       "7                                Bangalore/Bengaluru        5-8 Yrs   \n",
       "8                                Bangalore/Bengaluru        5-8 Yrs   \n",
       "9                                Bangalore/Bengaluru        6-8 Yrs   \n",
       "\n",
       "                job_salary  \n",
       "0  3,50,000 - 4,50,000 PA.  \n",
       "1  7,00,000 - 9,50,000 PA.  \n",
       "2            Not disclosed  \n",
       "3            Not disclosed  \n",
       "4            Not disclosed  \n",
       "5            Not disclosed  \n",
       "6            Not disclosed  \n",
       "7            Not disclosed  \n",
       "8            Not disclosed  \n",
       "9            Not disclosed  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def data_scientist_scrapes(url):\n",
    "\n",
    "    opts = Options()\n",
    "\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    #url = \"https://www.naukri.com/\"\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    driver.find_element_by_id('qsb-keyword-sugg').send_keys('Data Scientist')\n",
    "    driver.find_element_by_id('qsb-location-sugg').send_keys('Bangalore')\n",
    "\n",
    "    driver.find_element_by_class_name('btn').click()\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # scraping the data:\n",
    "\n",
    "    \n",
    "    job_titles, job_company = [],[]\n",
    "\n",
    "    job_location, job_exp_req, job_sal = [],[],[]\n",
    "\n",
    "    for title in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]:\n",
    "        job_titles.append(title.text)\n",
    "\n",
    "    for company_name in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[:10]:\n",
    "        job_company.append(company_name.text)\n",
    "\n",
    "    for i,value in enumerate(driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")):\n",
    "            if i%3 == 0:\n",
    "                job_exp_req.append(value.text)\n",
    "\n",
    "            if i%3 == 1:\n",
    "                job_sal.append(value.text)\n",
    "\n",
    "            if i%3 == 2:\n",
    "                job_location.append(value.text)\n",
    "                \n",
    "            if i>28:\n",
    "                break\n",
    "                \n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame({'job_title':job_titles,'job_company':job_company,'job_locations':job_location,'experience_req':job_exp_req,'job_salary':job_sal})\n",
    "\n",
    "    return df\n",
    "\n",
    "data_scientist_scrapes('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3-You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field \n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done \n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Driver [C:\\Users\\HP\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24\\chromedriver.exe] found in cache\n",
      "<ipython-input-59-76c73937693b>:17: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_company</th>\n",
       "      <th>job_locations</th>\n",
       "      <th>experience_req</th>\n",
       "      <th>job_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>5,00,000 - 6,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent opportunity For Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>50,000 - 3,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mobikwik</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>5,00,000 - 9,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>5,00,000 - 8,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Noida/ B'lore</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>4,00,000 - 9,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Cloudstrats Technologies Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                     Data Scientist   \n",
       "2  Data Scientist - High growth VC backed Influen...   \n",
       "3           Excellent opportunity For Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "6           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "7                             Data Scientist - Noida   \n",
       "8                     Data Scientist - Noida/ B'lore   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                         job_company  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                             IBM India Pvt. Limited   \n",
       "2                    Ravgins International Pvt. Ltd.   \n",
       "3              NEC CORPORATION INDIA PRIVATE LIMITED   \n",
       "4                                           Mobikwik   \n",
       "5  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...   \n",
       "6  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...   \n",
       "7     Optum Global Solutions (India) Private Limited   \n",
       "8              NEC CORPORATION INDIA PRIVATE LIMITED   \n",
       "9           Cloudstrats Technologies Private Limited   \n",
       "\n",
       "                                       job_locations experience_req  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...        0-3 Yrs   \n",
       "1  Noida, Hyderabad/Secunderabad, Bangalore/Benga...        4-9 Yrs   \n",
       "2  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...        3-5 Yrs   \n",
       "3                         Noida, Bangalore/Bengaluru        3-7 Yrs   \n",
       "4           New Delhi, Gurgaon/Gurugram, Delhi / NCR        3-5 Yrs   \n",
       "5                      Gurgaon/Gurugram, Delhi / NCR        3-6 Yrs   \n",
       "6                      Gurgaon/Gurugram, Delhi / NCR        3-6 Yrs   \n",
       "7                                              Noida        3-5 Yrs   \n",
       "8                         Noida, Bangalore/Bengaluru        3-8 Yrs   \n",
       "9  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...        5-8 Yrs   \n",
       "\n",
       "                job_salary  \n",
       "0  3,50,000 - 4,50,000 PA.  \n",
       "1            Not disclosed  \n",
       "2  5,00,000 - 6,00,000 PA.  \n",
       "3    50,000 - 3,00,000 PA.  \n",
       "4            Not disclosed  \n",
       "5  5,00,000 - 9,00,000 PA.  \n",
       "6  5,00,000 - 8,00,000 PA.  \n",
       "7            Not disclosed  \n",
       "8  4,00,000 - 9,00,000 PA.  \n",
       "9            Not disclosed  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def data_filter_scrape(url):\n",
    "\n",
    "    opts = Options()\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    #url = \"https://www.naukri.com/\"\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    driver.find_element_by_id('qsb-keyword-sugg').send_keys('Data Scientist')\n",
    "\n",
    "\n",
    "    driver.find_element_by_class_name('btn').click()\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    driver.find_element_by_xpath(\"//label[@for='chk-Delhi / NCR-cityTypeGid-']/i\").click()     # filter click for location\n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    driver.find_element_by_xpath(\"//label[@for='chk-3-6 Lakhs-ctcFilter-']/i\").click()     # filter click for salary range\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    # scraping the data:\n",
    "\n",
    "    job_titles, job_company = [],[]\n",
    "\n",
    "    job_location, job_exp_req, job_sal = [],[],[]\n",
    "\n",
    "    for title in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]:\n",
    "        job_titles.append(title.text)\n",
    "\n",
    "    for company_name in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[:10]:\n",
    "        job_company.append(company_name.text)\n",
    "\n",
    "    for i,value in enumerate(driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")):\n",
    "            if i%3 == 0:\n",
    "                job_exp_req.append(value.text)\n",
    "\n",
    "            if i%3 == 1:\n",
    "                job_sal.append(value.text)\n",
    "\n",
    "            if i%3 ==2:\n",
    "                job_location.append(value.text)\n",
    "                \n",
    "            if i>28:\n",
    "                break\n",
    "                \n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame({'job_title':job_titles,'job_company':job_company,'job_locations':job_location,'experience_req':job_exp_req,'job_salary':job_sal})\n",
    "\n",
    "    return df\n",
    "\n",
    "data_filter_scrape('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist \n",
    "Designation in Noida location. You have to scrape company_name, No. of days \n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” \n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page\n",
    "Then scrape the data for the first 10 jobs results you get in the above shown \n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Driver [C:\\Users\\HP\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24\\chromedriver.exe] found in cache\n",
      "<ipython-input-72-322cfda24cd4>:19: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//for[@class='css-2ku426']\"}\n  (Session info: chrome=90.0.4430.93)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-322cfda24cd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mres_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglassdoor_ds_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.glassdoor.co.in/index.htm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mres_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-322cfda24cd4>\u001b[0m in \u001b[0;36mglassdoor_ds_jobs\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//for[@class='css-2ku426']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//for[@class='css-2ku426']\"}\n  (Session info: chrome=90.0.4430.93)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "\n",
    "def glassdoor_ds_jobs(url):\n",
    "    opts = Options()\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    title_l,price_l,ratings_l = [],[],[]    \n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    company_l,days_l,rating_l = [],[],[]\n",
    "    counter = 0\n",
    "\n",
    "    time.sleep(2)\n",
    "    \n",
    "    driver.find_element_by_xpath(\"//for[@class='css-2ku426']\").click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    driver.find_element_by_id(\"userEmail\").send_keys('sharda.saransh@gmail.com')\n",
    "\n",
    "    driver.find_element_by_id(\"userPassword\").send_keys(\"786@saransh\")\n",
    "\n",
    "    driver.find_element_by_xpath(\"//button[@class='gd-ui-button minWidthBtn css-8i7bc2']\").click()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "    driver.find_elements_by_xpath(\"//input[@class='css-1xtvih1']\")[2].send_keys(Keys.CONTROL + \"a\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    driver.find_elements_by_xpath(\"//input[@class='css-1xtvih1']\")[2].send_keys('Noida')\n",
    "\n",
    "    driver.find_elements_by_xpath(\"//input[@class='css-1xtvih1']\")[1].send_keys('Data Scientist')\n",
    "\n",
    "    driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\").click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")[:10]:\n",
    "        days_l.append(i.text)\n",
    "\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class=' css-10l5u4p e1n63ojh0 jobLink']/span\")[:10]:\n",
    "        company_l.append(i.text)\n",
    "\n",
    "    for i in driver.find_elements_by_class_name(\"compactStars\")[:10]:\n",
    "        rating_l.append(i.text)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(list(zip(company_l,rating_l,days_l)),columns=['comapny','rating','days_since_posted'])\n",
    "\n",
    "    return df\n",
    "\n",
    "res_df = glassdoor_ds_jobs('https://www.glassdoor.co.in/index.htm')\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation \n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Driver [C:\\Users\\HP\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24\\chromedriver.exe] found in cache\n",
      "<ipython-input-97-b3bab1b71955>:16: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comapny</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>₹ 6,11,228/yr</td>\n",
       "      <td>₹ 6,11,228/yr</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,095K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>₹ 11,46,533/yr</td>\n",
       "      <td>₹ 11,46,533/yr</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>₹ 8,97,795/yr</td>\n",
       "      <td>₹ 8,97,795/yr</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>₹ 7,38,057/yr</td>\n",
       "      <td>₹ 7,38,057/yr</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>₹ 12,39,781/yr</td>\n",
       "      <td>₹ 12,39,781/yr</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>₹ 13,36,142/yr</td>\n",
       "      <td>₹ 13,36,142/yr</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>₹ 8,15,192/yr</td>\n",
       "      <td>₹ 8,15,192/yr</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>₹ 11,35,221/yr</td>\n",
       "      <td>₹ 11,35,221/yr</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>₹ 11,44,243/yr</td>\n",
       "      <td>₹ 11,44,243/yr</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>₹ 14,13,288/yr</td>\n",
       "      <td>₹ 14,13,288/yr</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          comapny      avg_salary min_salary max_salary\n",
       "0   ₹ 6,11,228/yr   ₹ 6,11,228/yr     ₹343K     ₹1,095K\n",
       "1  ₹ 11,46,533/yr  ₹ 11,46,533/yr     ₹577K     ₹2,213K\n",
       "2   ₹ 8,97,795/yr   ₹ 8,97,795/yr     ₹586K     ₹2,730K\n",
       "3   ₹ 7,38,057/yr   ₹ 7,38,057/yr     ₹355K     ₹1,613K\n",
       "4  ₹ 12,39,781/yr  ₹ 12,39,781/yr     ₹450K    ₹11,622K\n",
       "5  ₹ 13,36,142/yr  ₹ 13,36,142/yr   ₹1,069K     ₹1,520K\n",
       "6   ₹ 8,15,192/yr   ₹ 8,15,192/yr     ₹502K     ₹1,465K\n",
       "7  ₹ 11,35,221/yr  ₹ 11,35,221/yr     ₹202K     ₹1,809K\n",
       "8  ₹ 11,44,243/yr  ₹ 11,44,243/yr     ₹575K     ₹1,520K\n",
       "9  ₹ 14,13,288/yr  ₹ 14,13,288/yr   ₹1,014K     ₹2,149K"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "\n",
    "def glassdoor_ds_salaries(url):\n",
    "\n",
    "    opts = Options()\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    title_l,price_l,ratings_l = [],[],[]    \n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    avg_sal_l,min_sal_l,max_sal_l,company_l = [],[],[],[]\n",
    "    counter = 0\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "    driver.find_element_by_class_name(\"keyword\").send_keys('Data Scientist')\n",
    "\n",
    "    driver.find_element_by_class_name(\"loc\").send_keys(Keys.CONTROL + 'a')\n",
    "\n",
    "    driver.find_element_by_class_name(\"loc\").send_keys('Noida')\n",
    "\n",
    "    driver.find_element_by_class_name(\"gd-btn-mkt\").click()\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    sauce = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(sauce)\n",
    "\n",
    "    for i in soup.find_all('div',attrs={'class':\"col-2 d-none d-md-flex flex-row justify-content-end\"})[:10]:\n",
    "        avg_sal_l.append(i.text)\n",
    "\n",
    "    for i in soup.find_all('p',attrs={'class':\"d-block d-md-none m-0 css-1kuy7z7\"})[:10]:\n",
    "        element = i.text.strip('Range: ').split('-')\n",
    "        min_sal_l.append(element[0])\n",
    "        max_sal_l.append(element[1])\n",
    "\n",
    "    for n,i in enumerate(soup.find_all('p',attrs={'class':\"m-0\"})[2:60]):\n",
    "        if n%6 == 0:\n",
    "            company_l.append(i.text)    \n",
    "\n",
    "    df = pd.DataFrame(list(zip(company_l,avg_sal_l,min_sal_l,max_sal_l)),columns=['comapny','avg_salary','min_salary','max_salary'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "res_df = glassdoor_ds_salaries('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to \n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/90.0.4430.24/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\HP\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24]\n",
      "<ipython-input-110-b8795d8c3684>:16: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-b8795d8c3684>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[0mres_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msunglasses_flikpart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.flipkart.com/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[0mres_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-b8795d8c3684>\u001b[0m in \u001b[0;36msunglasses_flikpart\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mopts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             RemoteWebDriver.__init__(\n\u001b[0m\u001b[0;32m     77\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                 command_executor=ChromeRemoteConnection(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[0;32m    155\u001b[0m             warnings.warn(\"Please use FirefoxOptions to set browser profile\",\n\u001b[0;32m    156\u001b[0m                           DeprecationWarning, stacklevel=2)\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_switch_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSwitchTo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mobile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMobile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[1;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[0;32m    250\u001b[0m         parameters = {\"capabilities\": w3c_caps,\n\u001b[0;32m    251\u001b[0m                       \"desiredCapabilities\": capabilities}\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'sessionId'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             return self.request_encode_body(\n\u001b[0m\u001b[0;32m     80\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    424\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    419\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import time\n",
    "\n",
    "def sunglasses_flikpart(url):\n",
    "\n",
    "    opts = Options()\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    #url = \"https://www.flipkart.com/\"\n",
    "\n",
    "\n",
    "    brand, desc, price, discount = [],[],[],[]\n",
    "    counter = 0\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()  # close the login pop-up\n",
    "\n",
    "    driver.find_element_by_xpath(\"//input[@class='_3704LK']\").clear()\n",
    "    driver.find_element_by_xpath(\"//input[@class='_3704LK']\").send_keys('sunglasses',Keys.RETURN)  # search for sunglasses\n",
    "\n",
    "    window_before = driver.window_handles[0]\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    while counter < 101:\n",
    "\n",
    "        for block in driver.find_elements_by_xpath(\"//img[@class='_2r_T1I']\"):\n",
    "            block.click()\n",
    "            window_after = driver.window_handles[-1]\n",
    "\n",
    "            driver.switch_to.window(window_after)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            brand.append(driver.find_element_by_class_name(\"G6XhRU\").text)\n",
    "            desc.append(driver.find_element_by_class_name(\"B_NuCI\").text)\n",
    "            price.append(driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\").text)\n",
    "            discount.append(driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']/span\").text)    \n",
    "\n",
    "            driver.close()\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            driver.switch_to.window(window_before)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            #print(counter)\n",
    "\n",
    "\n",
    "        driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[-1].click()\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(list(zip(brand,price,discount,desc)),columns=['brand','price','discount','description'])\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "res_df = sunglasses_flikpart('https://www.flipkart.com/')\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7-Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import time\n",
    "\n",
    "def iphone_reviews_flikpart(url):\n",
    "\n",
    "    opts = Options()\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    #url = \"https://www.flipkart.com/\"\n",
    "\n",
    "    \n",
    "    rating_l,rev_summary_l,full_summary_l = [],[],[]\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    while counter < 11:\n",
    "\n",
    "\n",
    "        time.sleep(2)\n",
    "        \n",
    "        \n",
    "        for rating in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "            rating_l.append(rating.text)\n",
    "        \n",
    "        for rev_summary in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "            rev_summary_l.append(rev_summary.text)\n",
    "            \n",
    "        for full_summary in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "            full_summary_l.append(full_summary.text)\n",
    "             \n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[-1].click()\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(list(zip(rating_l,rev_summary_l,full_summary_l)),columns=['ratings','review_summary','full_summary'])\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "res_df = iphone_reviews_flikpart('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and \n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import time\n",
    "\n",
    "def sneakers_flikpart(url):\n",
    "\n",
    "    opts = Options()\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    #url = \"https://www.flipkart.com/\"\n",
    "\n",
    "\n",
    "    brand, desc, price, discount = [],[],[],[]\n",
    "    counter = 0\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()  # close the login pop-up\n",
    "\n",
    "    driver.find_element_by_xpath(\"//input[@class='_3704LK']\").clear()\n",
    "\n",
    "    driver.find_element_by_xpath(\"//input[@class='_3704LK']\").send_keys('sneakers',Keys.RETURN)  # search for sneakers\n",
    "\n",
    "    window_before = driver.window_handles[0]\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    while counter < 101:\n",
    "\n",
    "        for block in driver.find_elements_by_xpath(\"//img[@class='_2r_T1I']\"):\n",
    "            block.click()\n",
    "            window_after = driver.window_handles[-1]\n",
    "\n",
    "            driver.switch_to.window(window_after)\n",
    "\n",
    "            time.sleep(2)\n",
    "            \n",
    "\n",
    "            brand.append(driver.find_element_by_class_name(\"G6XhRU\").text)\n",
    "            desc.append(driver.find_element_by_class_name(\"B_NuCI\").text)\n",
    "            price.append(driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\").text)\n",
    "\n",
    "            try:\n",
    "                discount.append(driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']/span\").text)\n",
    "            except NoSuchElementException:\n",
    "                discount.append('None')\n",
    "\n",
    "\n",
    "            driver.close()\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            driver.switch_to.window(window_before)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        driver.find_elements_by_xpath(\"//a[@class='_3ywSr_']\")[-1].click()\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(list(zip(brand,price,discount,desc)),columns=['brand','price','discount','description'])\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "res_df = sneakers_flikpart('https://www.flipkart.com/')\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in \n",
    "the below image\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of \n",
    "the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def sneaker_filter_scrape_myn(url):\n",
    "    opts = Options()\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    \n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    driver.find_element_by_xpath(\"//price-input[@value='6657.0 TO 13105.0']/\").click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_xpath(\"//input[@value='Black']/following-sibling::div\").click()\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    window_before = driver.window_handles[0]\n",
    "\n",
    "    brand, desc, price= [],[],[]\n",
    "    counter = 0\n",
    "\n",
    "    while counter < 3:\n",
    "\n",
    "        for block in driver.find_elements_by_xpath(\"//div[@class='product-sliderContainer']\"):\n",
    "            block.click()\n",
    "            window_after = driver.window_handles[-1]\n",
    "\n",
    "            driver.switch_to.window(window_after)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "\n",
    "            brand.append(driver.find_element_by_xpath(\"//h1[@class='pdp-title']\").text)\n",
    "            desc.append(driver.find_element_by_xpath(\"//h1[@class='pdp-name']\").text)\n",
    "            price.append(driver.find_element_by_xpath(\"//span/strong\").text)\n",
    "\n",
    "\n",
    "            driver.close()\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            driver.switch_to.window(window_before)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "        driver.find_element_by_xpath(\"//a[@rel='next']\").click()\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(list(zip(brand,price,desc)),columns=['brand','price','description'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "res_df = sneaker_filter_scrape_myn('https://www.myntra.com/shoes')\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the \n",
    "below image\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes \n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Driver [C:\\Users\\HP\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24\\chromedriver.exe] found in cache\n",
      "<ipython-input-78-f59a4ad29c25>:19: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS ZenBook Flip S OLED, Intel Evo Core i7-11...</td>\n",
       "      <td>1,49,990</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Swift 5 14\" (35.56cms) Full HD IPS Displa...</td>\n",
       "      <td>91,999</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>3,43,099</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>1,35,490</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell G3 3500 Gaming Laptop 15.6'' FHD 120Hz Di...</td>\n",
       "      <td>95,993</td>\n",
       "      <td>Not_rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...</td>\n",
       "      <td>?</td>\n",
       "      <td>Not_rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ASUS ROG Zephyrus M15 (2020), 15.6\" FHD 240Hz/...</td>\n",
       "      <td>1,18,990</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>MSI WF75, Intel 10th Gen. i7-10750HH, 17.3\" FH...</td>\n",
       "      <td>1,99,990</td>\n",
       "      <td>Not_rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DELL Inspiron G3 3590 15.6-inch Laptop (9th Ge...</td>\n",
       "      <td>?</td>\n",
       "      <td>2.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lenovo Ideapad 720s Intel Core i7 8th Gen 13.3...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title     price  \\\n",
       "0   ASUS ZenBook Flip S OLED, Intel Evo Core i7-11...  1,49,990   \n",
       "1   Acer Swift 5 14\" (35.56cms) Full HD IPS Displa...    91,999   \n",
       "2   Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...  3,43,099   \n",
       "3   Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  1,35,490   \n",
       "4   Dell G3 3500 Gaming Laptop 15.6'' FHD 120Hz Di...    95,993   \n",
       "..                                                ...       ...   \n",
       "95  (Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...         ?   \n",
       "96  ASUS ROG Zephyrus M15 (2020), 15.6\" FHD 240Hz/...  1,18,990   \n",
       "97  MSI WF75, Intel 10th Gen. i7-10750HH, 17.3\" FH...  1,99,990   \n",
       "98  DELL Inspiron G3 3590 15.6-inch Laptop (9th Ge...         ?   \n",
       "99  Lenovo Ideapad 720s Intel Core i7 8th Gen 13.3...    89,990   \n",
       "\n",
       "               ratings  \n",
       "0   4.5 out of 5 stars  \n",
       "1   4.4 out of 5 stars  \n",
       "2   5.0 out of 5 stars  \n",
       "3   4.3 out of 5 stars  \n",
       "4            Not_rated  \n",
       "..                 ...  \n",
       "95           Not_rated  \n",
       "96  3.7 out of 5 stars  \n",
       "97           Not_rated  \n",
       "98  2.9 out of 5 stars  \n",
       "99  3.1 out of 5 stars  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def laptops_i7i9_amz(url):\n",
    "\n",
    "    opts = Options()\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=opts)\n",
    "\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36\")\n",
    "\n",
    "    title_l,price_l,ratings_l = [],[],[]    \n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    driver.find_element_by_xpath(\"//input[@id='twotabsearchtextbox']\").send_keys('Laptop',Keys.RETURN)\n",
    "\n",
    "\n",
    "    driver.find_element_by_xpath(\"//li[@aria-label='Intel Core i7']/span\").click()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        for i in soup.find_all('div',attrs={'data-component-type':'s-search-result'}):\n",
    "            title_l.append(i.find('span',attrs={'class' :'a-size-medium a-color-base a-text-normal'}).text)\n",
    "\n",
    "            p = i.find('span',attrs={'class':'a-price-whole'})\n",
    "            if p is not None:            \n",
    "                price_l.append(i.find('span',attrs={'class':'a-price-whole'}).text)\n",
    "            else:\n",
    "                price_l.append('?')\n",
    "\n",
    "            z = i.find('span',attrs={'class':'a-icon-alt'})            \n",
    "            if z is not None:    \n",
    "                ratings_l.append(i.find('span',attrs={'class':'a-icon-alt'}).text)\n",
    "            else:\n",
    "                ratings_l.append('Not_rated')\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            if counter > 99:\n",
    "                break\n",
    "\n",
    "\n",
    "        if counter > 99:\n",
    "            break\n",
    "\n",
    "\n",
    "        driver.find_element_by_xpath(\"//li[@class='a-last']\").click()\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(list(zip(title_l,price_l,ratings_l)),columns=['title','price','ratings'])\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "res_df = laptops_i7i9_amz('https://www.amazon.in/')\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
